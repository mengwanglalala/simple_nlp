{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([2, 6]), tensor([5, 7, 2, 6])] [tensor([5, 4, 6, 4]), tensor([4, 6, 2])]\n",
      "tensor([[4, 5, 0, 0, 0],\n",
      "        [4, 7, 4, 1, 0]]) tensor([[1, 6, 5, 4, 0],\n",
      "        [7, 5, 7, 0, 0]])\n",
      "Parameter containing:\n",
      "tensor([[ 0.5007, -0.6072,  1.4729,  0.7890, -2.5997,  0.8715, -1.5055,  0.4766],\n",
      "        [-1.6439, -0.0193, -2.2346,  0.2380,  0.1550,  0.7215,  0.9870,  0.2234],\n",
      "        [-0.3531, -0.1405,  2.8583, -0.5569,  0.8372,  0.8181, -2.1133, -1.4057],\n",
      "        [ 1.0030, -0.7196,  0.5070, -1.4659,  1.1403, -0.5032, -0.1697,  0.7919],\n",
      "        [-0.2741,  0.8439, -0.1827,  0.7454,  0.6124,  1.8913, -1.1633, -1.0219],\n",
      "        [-1.0601, -0.5914, -0.0971, -0.0617,  0.1567,  0.4215,  0.1492, -0.7813],\n",
      "        [ 1.3599, -0.0714,  0.7039,  0.1371,  1.2803,  0.4825, -1.3490, -0.2893],\n",
      "        [ 1.0081,  0.2055,  0.1695,  1.7350, -0.4631,  0.6384,  0.4213, -0.8453],\n",
      "        [-0.0170, -0.0956,  0.0819, -0.7202,  0.3002, -0.9604, -0.6468,  0.4037]],\n",
      "       requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.5677, -0.3175,  0.0145,  0.8478,  0.5012,  0.3512, -0.5572,\n",
       "           0.4904],\n",
       "         [ 0.1843, -0.5942,  1.9065,  0.1691,  1.1364, -0.5440, -0.1600,\n",
       "           0.1765],\n",
       "         [-2.4392, -0.4121,  0.1469,  1.6484, -0.0195, -0.9276,  0.4236,\n",
       "           0.9293],\n",
       "         [-1.5272,  0.4483, -0.4281,  0.6895,  1.9367,  1.8631, -0.7039,\n",
       "           0.2041],\n",
       "         [-0.0370, -0.7241,  0.0857,  0.2976,  0.3212, -0.5430, -0.6288,\n",
       "          -0.0308]],\n",
       "\n",
       "        [[ 1.5621,  0.6090, -0.6689, -1.0925,  0.2479, -0.2435, -1.8772,\n",
       "           0.7904],\n",
       "         [-2.4392, -0.4121,  0.1469,  1.6484, -0.0195, -0.9276,  0.4236,\n",
       "           0.9293],\n",
       "         [ 1.5621,  0.6090, -0.6689, -1.0925,  0.2479, -0.2435, -1.8772,\n",
       "           0.7904],\n",
       "         [-0.0370, -0.7241,  0.0857,  0.2976,  0.3212, -0.5430, -0.6288,\n",
       "          -0.0308],\n",
       "         [-0.0370, -0.7241,  0.0857,  0.2976,  0.3212, -0.5430, -0.6288,\n",
       "          -0.0308]]], grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 关于word embedding， 以序列建模为例\n",
    "# 考虑source sentence 和target sentence\n",
    "# 构建序列，序列字符以索引形式表示\n",
    "batch_size = 2\n",
    "\n",
    "# 单词表大小\n",
    "max_num_src_words = 8\n",
    "max_num_tgt_words = 8\n",
    "model_dim = 8#源模型是512，embedding维度\n",
    "# 最大序列长度\n",
    "max_src_seq_len = 5\n",
    "max_tgt_seq_len = 5\n",
    "# src_len = torch.randint(2,5,(batch_size,))\n",
    "# tat_len = torch.randint(2,5,(batch_size,))\n",
    "src_len = torch.Tensor([2,4]).to(torch.int32)\n",
    "tgt_len = torch.Tensor([4,3]).to(torch.int32)\n",
    "\n",
    "# 单词索引构成的句子\n",
    "src_seq = [torch.randint(1,max_num_src_words,(L,)) for L in src_len]# 单词索引序列\n",
    "tgt_seq = [torch.randint(1,max_num_src_words,(L,)) for L in tgt_len]\n",
    "print(src_seq,tgt_seq)\n",
    "# 构建batch,单词索引构成源句子和目标句子，并做了padding，默认值为0\n",
    "src_seq = [F.pad(torch.randint(1,max_num_src_words,(L,)),(0,max_src_seq_len-L))for L in src_len]# 元组(0,max_src_seq_len-L)：左边pad多少位右边pad多少位\n",
    "src_seq = torch.cat([torch.unsqueeze(F.pad(torch.randint(1,max_num_src_words,(L,)),(0,max_src_seq_len-L)),0) for L in src_len])\n",
    "tgt_seq = torch.cat([torch.unsqueeze(F.pad(torch.randint(1,max_num_tgt_words,(L,)),(0,max_tgt_seq_len-L)),0) for L in tgt_len])\n",
    "print(src_seq,tgt_seq)\n",
    "\n",
    "# 构造embedding\n",
    "src_embedding_table = nn.Embedding(max_num_src_words+1,model_dim)\n",
    "tgt_embedding_table = nn.Embedding(max_num_tgt_words+1,model_dim)\n",
    "\n",
    "print(src_embedding_table.weight)\n",
    "\n",
    "src_embedding = src_embedding_table(src_seq)\n",
    "tgt_embedding = tgt_embedding_table(tgt_seq)\n",
    "tgt_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4],\n",
      "        [5]])\n",
      "tensor([[   1.,   10.,  100., 1000.]])\n",
      "tensor([[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
      "          1.0000e+00,  0.0000e+00,  1.0000e+00],\n",
      "        [ 8.4147e-01,  5.4030e-01,  9.9833e-02,  9.9500e-01,  9.9998e-03,\n",
      "          9.9995e-01,  1.0000e-03,  1.0000e+00],\n",
      "        [ 9.0930e-01, -4.1615e-01,  1.9867e-01,  9.8007e-01,  1.9999e-02,\n",
      "          9.9980e-01,  2.0000e-03,  1.0000e+00],\n",
      "        [ 1.4112e-01, -9.8999e-01,  2.9552e-01,  9.5534e-01,  2.9995e-02,\n",
      "          9.9955e-01,  3.0000e-03,  1.0000e+00],\n",
      "        [-7.5680e-01, -6.5364e-01,  3.8942e-01,  9.2106e-01,  3.9989e-02,\n",
      "          9.9920e-01,  4.0000e-03,  9.9999e-01],\n",
      "        [-9.5892e-01,  2.8366e-01,  4.7943e-01,  8.7758e-01,  4.9979e-02,\n",
      "          9.9875e-01,  5.0000e-03,  9.9999e-01]])\n",
      "Parameter containing:\n",
      "tensor([[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
      "          1.0000e+00,  0.0000e+00,  1.0000e+00],\n",
      "        [ 8.4147e-01,  5.4030e-01,  9.9833e-02,  9.9500e-01,  9.9998e-03,\n",
      "          9.9995e-01,  1.0000e-03,  1.0000e+00],\n",
      "        [ 9.0930e-01, -4.1615e-01,  1.9867e-01,  9.8007e-01,  1.9999e-02,\n",
      "          9.9980e-01,  2.0000e-03,  1.0000e+00],\n",
      "        [ 1.4112e-01, -9.8999e-01,  2.9552e-01,  9.5534e-01,  2.9995e-02,\n",
      "          9.9955e-01,  3.0000e-03,  1.0000e+00],\n",
      "        [-7.5680e-01, -6.5364e-01,  3.8942e-01,  9.2106e-01,  3.9989e-02,\n",
      "          9.9920e-01,  4.0000e-03,  9.9999e-01],\n",
      "        [-9.5892e-01,  2.8366e-01,  4.7943e-01,  8.7758e-01,  4.9979e-02,\n",
      "          9.9875e-01,  5.0000e-03,  9.9999e-01]])\n",
      "tensor([[[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
      "           1.0000e+00,  0.0000e+00,  1.0000e+00],\n",
      "         [ 8.4147e-01,  5.4030e-01,  9.9833e-02,  9.9500e-01,  9.9998e-03,\n",
      "           9.9995e-01,  1.0000e-03,  1.0000e+00],\n",
      "         [ 9.0930e-01, -4.1615e-01,  1.9867e-01,  9.8007e-01,  1.9999e-02,\n",
      "           9.9980e-01,  2.0000e-03,  1.0000e+00],\n",
      "         [ 1.4112e-01, -9.8999e-01,  2.9552e-01,  9.5534e-01,  2.9995e-02,\n",
      "           9.9955e-01,  3.0000e-03,  1.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
      "           1.0000e+00,  0.0000e+00,  1.0000e+00],\n",
      "         [ 8.4147e-01,  5.4030e-01,  9.9833e-02,  9.9500e-01,  9.9998e-03,\n",
      "           9.9995e-01,  1.0000e-03,  1.0000e+00],\n",
      "         [ 9.0930e-01, -4.1615e-01,  1.9867e-01,  9.8007e-01,  1.9999e-02,\n",
      "           9.9980e-01,  2.0000e-03,  1.0000e+00],\n",
      "         [ 1.4112e-01, -9.8999e-01,  2.9552e-01,  9.5534e-01,  2.9995e-02,\n",
      "           9.9955e-01,  3.0000e-03,  1.0000e+00]]])\n"
     ]
    }
   ],
   "source": [
    "# 构造position embedding\n",
    "max_position_len = 6\n",
    "pos_mat = torch.arange(max_position_len).reshape((-1,1))\n",
    "print(pos_mat)\n",
    "i_mat = torch.pow(10000,torch.arange(0,8,2).reshape((1,-1))/model_dim)\n",
    "print(i_mat)\n",
    "pe_embedding_table = torch.zeros(max_position_len,model_dim)\n",
    "pe_embedding_table[:, 0::2] = torch.sin(pos_mat/i_mat)#偶数列\n",
    "pe_embedding_table[:, 1::2] = torch.cos(pos_mat/i_mat)#奇数列\n",
    "print(pe_embedding_table)\n",
    "pe_embedding = nn.Embedding(max_position_len,model_dim)\n",
    "pe_embedding.weight = nn.Parameter(pe_embedding_table,requires_grad=False)\n",
    "print(pe_embedding.weight)\n",
    "src_pos = torch.cat([torch.unsqueeze(torch.arange(max_src_seq_len),0) for _ in src_len]).to(torch.int32)\n",
    "tgt_pos = torch.cat([torch.unsqueeze(torch.arange(max_tgt_seq_len),0) for _ in tgt_len]).to(torch.int32)\n",
    "\n",
    "src_pe_embedding = pe_embedding(src_pos)\n",
    "tgt_pe_emebdding = pe_embedding(tgt_pos)\n",
    "print(tgt_pe_emebdding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.4421, -1.1066, -1.4678,  0.0533,  0.8438])\n",
      "tensor([0.1835, 0.1898, 0.1830, 0.2131, 0.2306]) tensor([1.1807e-10, 3.3821e-09, 9.1314e-11, 3.6867e-04, 9.9963e-01])\n"
     ]
    }
   ],
   "source": [
    "# softmax演示， scale的重要性\n",
    "score = torch.randn(5)\n",
    "print(score)\n",
    "alpha1 = 0.1\n",
    "alpha2 = 10\n",
    "prob1 = F.softmax(score*alpha1,-1)\n",
    "prob2 = F.softmax(score*alpha2,-1)\n",
    "print(prob1,prob2)# 可以看到softmax函数输入值越大，其方差越大，这也是为什么attention中要进行根号dk缩放。类似雅可比矩阵也会都变的很小，导致梯度消失\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5, 1])\n",
      "tensor([[[1., 1., 0., 0., 0.],\n",
      "         [1., 1., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 0.],\n",
      "         [1., 1., 1., 1., 0.],\n",
      "         [1., 1., 1., 1., 0.],\n",
      "         [1., 1., 1., 1., 0.],\n",
      "         [0., 0., 0., 0., 0.]]])\n",
      "tensor([[[False, False,  True,  True,  True],\n",
      "         [False, False,  True,  True,  True],\n",
      "         [ True,  True,  True,  True,  True],\n",
      "         [ True,  True,  True,  True,  True],\n",
      "         [ True,  True,  True,  True,  True]],\n",
      "\n",
      "        [[False, False, False, False,  True],\n",
      "         [False, False, False, False,  True],\n",
      "         [False, False, False, False,  True],\n",
      "         [False, False, False, False,  True],\n",
      "         [ True,  True,  True,  True,  True]]])\n",
      "tensor([[[-0.6656,  0.1447,  2.5085,  1.0907, -1.7251],\n",
      "         [-1.0825,  1.4406, -0.6529, -0.6054,  0.1158],\n",
      "         [-1.3831, -0.0417, -0.6725, -0.8332,  0.2140],\n",
      "         [-0.1505,  3.3522, -0.1118, -0.4893,  0.8341],\n",
      "         [-1.9256,  1.0686, -0.6746,  1.0181, -1.5364]],\n",
      "\n",
      "        [[-0.6538, -2.7563,  0.0153,  0.0854,  1.9723],\n",
      "         [ 0.5242, -0.0903,  1.0427, -0.9778, -0.8427],\n",
      "         [-0.4466,  1.1865,  0.8144,  0.3193,  0.0036],\n",
      "         [-1.5103,  0.2315, -0.0130,  0.6298, -1.1792],\n",
      "         [-0.1832,  0.8860, -0.3683,  2.1041,  0.1345]]])\n",
      "tensor([[[-6.6557e-01,  1.4474e-01, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
      "         [-1.0825e+00,  1.4406e+00, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
      "         [-1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
      "         [-1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
      "         [-1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09]],\n",
      "\n",
      "        [[-6.5385e-01, -2.7563e+00,  1.5349e-02,  8.5407e-02, -1.0000e+09],\n",
      "         [ 5.2421e-01, -9.0323e-02,  1.0427e+00, -9.7779e-01, -1.0000e+09],\n",
      "         [-4.4656e-01,  1.1865e+00,  8.1443e-01,  3.1933e-01, -1.0000e+09],\n",
      "         [-1.5103e+00,  2.3154e-01, -1.3026e-02,  6.2983e-01, -1.0000e+09],\n",
      "         [-1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09]]])\n",
      "tensor([[[0.3078, 0.6922, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0743, 0.9257, 0.0000, 0.0000, 0.0000],\n",
      "         [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
      "         [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
      "         [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]],\n",
      "\n",
      "        [[0.1935, 0.0236, 0.3778, 0.4052, 0.0000],\n",
      "         [0.2904, 0.1571, 0.4878, 0.0647, 0.0000],\n",
      "         [0.0847, 0.4339, 0.2991, 0.1823, 0.0000],\n",
      "         [0.0508, 0.2901, 0.2271, 0.4320, 0.0000],\n",
      "         [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]]])\n"
     ]
    }
   ],
   "source": [
    "# 构造self attention 的 mask\n",
    "# mask的shape： 【batch_size, max_src_len, max_src_len】,值为1或-inf\n",
    "valid_encoder_pos = torch.unsqueeze(torch.cat([torch.unsqueeze(F.pad(torch.ones(L),(0,max_src_seq_len-L)),0) for L in src_len]),2)\n",
    "print(valid_encoder_pos.shape)# 有效位置\n",
    "valid_encoder_pos_matrix = torch.bmm(valid_encoder_pos,valid_encoder_pos.transpose(1,2))#两个有效矩阵相乘，计算出两两相关性\n",
    "print(valid_encoder_pos_matrix)\n",
    "invalid_encoder_pos = 1 - valid_encoder_pos_matrix\n",
    "mask_encoder_self_attention = invalid_encoder_pos.to(torch.bool)\n",
    "print(mask_encoder_self_attention)\n",
    "\n",
    "# 举个例子\n",
    "score = torch.randn(batch_size, max_src_seq_len,max_src_seq_len)\n",
    "masked_score = score.masked_fill(mask_encoder_self_attention,-1e9)\n",
    "prob = F.softmax(masked_score,-1)\n",
    "print(score)\n",
    "print(masked_score)\n",
    "print(prob)#可以看到pad的地方都为0，被mask调了。第三个和第四个单词均衡的原因是因为都被mask掉了，计算出的是均匀权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5, 1])\n",
      "tensor([[[1., 1., 0., 0., 0.],\n",
      "         [1., 1., 0., 0., 0.],\n",
      "         [1., 1., 0., 0., 0.],\n",
      "         [1., 1., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 0.],\n",
      "         [1., 1., 1., 1., 0.],\n",
      "         [1., 1., 1., 1., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]]])\n",
      "tensor([[[False, False,  True,  True,  True],\n",
      "         [False, False,  True,  True,  True],\n",
      "         [False, False,  True,  True,  True],\n",
      "         [False, False,  True,  True,  True],\n",
      "         [ True,  True,  True,  True,  True]],\n",
      "\n",
      "        [[False, False, False, False,  True],\n",
      "         [False, False, False, False,  True],\n",
      "         [False, False, False, False,  True],\n",
      "         [ True,  True,  True,  True,  True],\n",
      "         [ True,  True,  True,  True,  True]]])\n"
     ]
    }
   ],
   "source": [
    "# 构造intra attention 的mask\n",
    "# Q @ K^T shape： 【batch_size, tgt_seq_len, src_seq_len】\n",
    "valid_encoder_pos = torch.unsqueeze(torch.cat([torch.unsqueeze(F.pad(torch.ones(L),(0,max_src_seq_len-L)),0) for L in src_len]),2)\n",
    "valid_dencoder_pos = torch.unsqueeze(torch.cat([torch.unsqueeze(F.pad(torch.ones(L),(0,max_tgt_seq_len-L)),0) for L in tgt_len]),2)\n",
    "print(valid_dencoder_pos.shape)\n",
    "valid_cross_pos = torch.bmm(valid_dencoder_pos,valid_encoder_pos.transpose(1,2))\n",
    "print(valid_cross_pos)\n",
    "invalid_cross_pos = 1- valid_cross_pos\n",
    "mask_cross_attention = invalid_cross_pos.to(torch.bool)\n",
    "print(mask_cross_attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5, 5])\n",
      "tensor([[[1., 0., 0., 0., 0.],\n",
      "         [1., 1., 0., 0., 0.],\n",
      "         [1., 1., 1., 0., 0.],\n",
      "         [1., 1., 1., 1., 0.],\n",
      "         [0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0.],\n",
      "         [1., 1., 0., 0., 0.],\n",
      "         [1., 1., 1., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]]])\n",
      "tensor([[[False,  True,  True,  True,  True],\n",
      "         [False, False,  True,  True,  True],\n",
      "         [False, False, False,  True,  True],\n",
      "         [False, False, False, False,  True],\n",
      "         [ True,  True,  True,  True,  True]],\n",
      "\n",
      "        [[False,  True,  True,  True,  True],\n",
      "         [False, False,  True,  True,  True],\n",
      "         [False, False, False,  True,  True],\n",
      "         [ True,  True,  True,  True,  True],\n",
      "         [ True,  True,  True,  True,  True]]])\n",
      "tensor([[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.9115, 0.0885, 0.0000, 0.0000, 0.0000],\n",
      "         [0.2252, 0.4641, 0.3107, 0.0000, 0.0000],\n",
      "         [0.0669, 0.0874, 0.6038, 0.2419, 0.0000],\n",
      "         [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]],\n",
      "\n",
      "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.2610, 0.7390, 0.0000, 0.0000, 0.0000],\n",
      "         [0.7632, 0.0979, 0.1389, 0.0000, 0.0000],\n",
      "         [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
      "         [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]]])\n"
     ]
    }
   ],
   "source": [
    "# 构造decoder self attention的mask\n",
    "valid_decoder_tri_matrix = torch.cat([torch.unsqueeze(F.pad(torch.tril(torch.ones((L,L))),\\\n",
    "    (0,max_tgt_seq_len-L,0,max_tgt_seq_len-L)),0) for L in tgt_len])\n",
    "print(valid_decoder_tri_matrix.shape)\n",
    "print(valid_decoder_tri_matrix)\n",
    "invalid_decoder_tri_matrix = 1- valid_decoder_tri_matrix\n",
    "invalid_decoder_tri_matrix = invalid_decoder_tri_matrix.to(torch.bool)\n",
    "print(invalid_decoder_tri_matrix)\n",
    "# 举个例子\n",
    "score = torch.randn(batch_size, max_tgt_seq_len,max_tgt_seq_len)\n",
    "masked_score = score.masked_fill(invalid_decoder_tri_matrix,-1e9)\n",
    "prob = F.softmax(masked_score,-1)\n",
    "print(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建scaled self attention\n",
    "def scaled_dot_product_attention(Q,K,V,attn_mask):\n",
    "    # shape of Q,K,V : (batch_size*num_head, seq_len, model_dim/num_head)\n",
    "    score = torch.bmm(Q,K.traspose(-2,-1))/torch.sqrt(model_dim)\n",
    "    masked_score = score.masked_fill(attn_mask,-1)\n",
    "    prob = F.softmax(masked_score,-1)\n",
    "    context = torch.bmm(prob,V)\n",
    "    return context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a2e8f04d65c62c49dbc0f2adda76bbd103f82c3255fc54c7e3855bd92e2af645"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
