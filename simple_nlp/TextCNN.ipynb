{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "import torch.nn.functional as F\n",
    "\n",
    "dtype = torch.FloatTensor\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 words sentences (=sequence_length is 3)\n",
    "sentences = [\"i love you\", \"he loves me\", \"she likes baseball\", \"i hate you\", \"sorry for that\", \"this is awful\"]\n",
    "labels = [1, 1, 1, 0, 0, 0]  # 1 is good, 0 is not good.\n",
    "embedding_size = 2 #训练样本比较少，不需要太高维度\n",
    "sequence_length = len(sentences[0]) # 如果句子不等长则需要padding\n",
    "num_classes = len(set(labels))\n",
    "batch_size = 3\n",
    "\n",
    "word_list = \" \".join(sentences).split()\n",
    "vocab = list(set(word_list))\n",
    "word2idx = {w: i for i, w in enumerate(vocab)}\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(sentences,labels):\n",
    "    inputs = []\n",
    "    for sen in sentences:\n",
    "        inputs.append([word2idx[n] for n in sen.split()])\n",
    "    return inputs, labels\n",
    "\n",
    "input_data, output_data = make_data(sentences,labels)\n",
    "input_data, output_data = torch.LongTensor(input_data), torch.LongTensor(output_data)\n",
    "dataset = Data.TensorDataset(input_data, output_data)\n",
    "loader = Data.DataLoader(dataset, batch_size, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TextCNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim= embedding_size)\n",
    "        output_channels = 3\n",
    "        self.conv = nn.Sequential(\n",
    "            # conv : [input_channel(=1), output_channel, (filter_height, filter_width), stride=1]\n",
    "            nn.Conv2d(1,output_channels,(2, embedding_size)), #每两个词做一个conv # => [batch_size, output_channel, 2, 1]\n",
    "            nn.ReLU(),\n",
    "            # pool : ((filter_height, filter_width))\n",
    "            nn.MaxPool2d((2,1)),\n",
    "        )\n",
    "        self.fc = nn.Linear(output_channels, num_classes)\n",
    "    def forward(self,x):\n",
    "        '''\n",
    "        X: [batch_size, sequence_length]\n",
    "        '''\n",
    "        batch_size = x.shape[0]\n",
    "        embedding1 = self.embedding(x) # [batch_size, sequence_length, embedding_size]\n",
    "        embedding1 = embedding1.unsqueeze(1) # add channel(=1) [batch, channel(=1), sequence_length, embedding_size]\n",
    "        conved = self.conv(embedding1) # [batch_size, output_channel, 1, 1]\n",
    "        flatten = conved.view(batch_size,-1) # [batch_size, output_channel*1*1]\n",
    "        out = self.fc(flatten)\n",
    "        return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1000 loss = 0.069539\n",
      "Epoch: 1000 loss = 0.001121\n",
      "Epoch: 2000 loss = 0.020395\n",
      "Epoch: 2000 loss = 0.000258\n",
      "Epoch: 3000 loss = 0.007320\n",
      "Epoch: 3000 loss = 0.000051\n",
      "Epoch: 4000 loss = 0.002826\n",
      "Epoch: 4000 loss = 0.000016\n",
      "Epoch: 5000 loss = 0.000004\n",
      "Epoch: 5000 loss = 0.001125\n"
     ]
    }
   ],
   "source": [
    "model = TextCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Training\n",
    "for epoch in range(5000):\n",
    "  for batch_x, batch_y in loader:\n",
    "    batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "    pred = model(batch_x)\n",
    "    loss = criterion(pred, batch_y)\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print('Epoch:', '%04d' % (epoch + 1), 'loss =', '{:.6f}'.format(loss))\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i hate me is Bad Mean...\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "test_text = 'i hate me'\n",
    "tests = [[word2idx[n] for n in test_text.split()]]\n",
    "test_batch = torch.LongTensor(tests).to(device)\n",
    "# Predict\n",
    "model = model.eval()\n",
    "predict = model(test_batch).data.max(1, keepdim=True)[1]\n",
    "if predict[0][0] == 0:\n",
    "    print(test_text,\"is Bad Mean...\")\n",
    "else:\n",
    "    print(test_text,\"is Good Mean!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "def min_days_to_grow_m_grass(m, n, points):\n",
    "    # 创建空的二维平面\n",
    "    grid = [[0] * 1000000001 for _ in range(1000000001)]\n",
    "    # 将所有草的初始位置标记为“已生长”\n",
    "    for x, y in points:\n",
    "        grid[x][y] = 1\n",
    "    # BFS 遍历\n",
    "    days = 0\n",
    "    queue = deque(points)\n",
    "    while queue:\n",
    "        size = len(queue)\n",
    "        for _ in range(size):\n",
    "            x, y = queue.popleft()\n",
    "            for dx, dy in [(0, 1), (0, -1), (1, 0), (-1, 0), (1, 1), (-1, -1), (1, -1), (-1, 1)]:\n",
    "                nx, ny = x + dx, y + dy\n",
    "                if nx >= 0 and ny >= 0 and nx <= 1000000000 and ny <= 1000000000 and not grid[nx][ny]:\n",
    "                    grid[nx][ny] = 1\n",
    "                    queue.append((nx, ny))\n",
    "        days += 1\n",
    "        # 检查是否已经找到至少 M 种草\n",
    "        for x, y in queue:\n",
    "            count = 0\n",
    "            for dx, dy in [(0, 1), (0, -1), (1, 0), (-1, 0), (1, 1), (-1, -1), (1, -1), (-1, 1)]:\n",
    "                nx, ny = x + dx, y + dy\n",
    "                if nx >= 0 and ny >= 0 and nx <= 1000000000 and ny <= 1000000000 and grid[nx][ny]:\n",
    "                    count += 1\n",
    "            if count >= m:\n",
    "                return days\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'find_point_with_m_grass' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-1256bc89b824>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# 输出\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# 所有草都在同一点，因此第0天就可以找到一点至少有3种草\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfind_point_with_m_grass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpoints\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 输出: 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# 修改第5朵草的位置\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'find_point_with_m_grass' is not defined"
     ]
    }
   ],
   "source": [
    "# 输入\n",
    "M = 3\n",
    "n = 5\n",
    "points = [[0, 0], [1, 1], [1, 0], [0, 1], [2, 2]]\n",
    "\n",
    "# 输出\n",
    "# 所有草都在同一点，因此第0天就可以找到一点至少有3种草\n",
    "print(find_point_with_m_grass(M, n, points))  # 输出: 0\n",
    "\n",
    "# 修改第5朵草的位置\n",
    "points[4] = [0, 2]\n",
    "\n",
    "# 输出\n",
    "# 第1天时，(0,1)这个点有3种草\n",
    "print(find_point_with_m_grass(M, n, points))  # 输出: 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "class Solution:\n",
    "    def __init__(self, M, n, points):\n",
    "        self.M = M\n",
    "        self.n = n\n",
    "        self.points = points\n",
    "        self.days = 0\n",
    "        self.visited = set()\n",
    "        self.adjacent = [(0, 1), (0, -1), (1, 0), (-1, 0), (1, 1), (1, -1), (-1, 1), (-1, -1)]\n",
    "        \n",
    "    def is_valid(self, x, y):\n",
    "        return 1 <= x <= 10**9 and 1 <= y <= 10**9\n",
    "    \n",
    "    def bfs(self, heap):\n",
    "        while heap:\n",
    "            curr = heapq.heappop(heap)\n",
    "            x, y, types = curr\n",
    "            if len(types) >= self.M:\n",
    "                return self.days\n",
    "            for dx, dy in self.adjacent:\n",
    "                nx, ny = x + dx, y + dy\n",
    "                if (nx, ny) not in self.visited and self.is_valid(nx, ny):\n",
    "                    self.visited.add((nx, ny))\n",
    "                    for p in self.points:\n",
    "                        if p == [nx, ny] or p in types:\n",
    "                            heapq.heappush(heap, (nx, ny, types | set([tuple(p)])))\n",
    "        return 0\n",
    "    \n",
    "    def find_min_days(self):\n",
    "        heap = []\n",
    "        for p in self.points:\n",
    "            heap.append((p[0], p[1], set([tuple(p)])))\n",
    "            self.visited.add(tuple(p))\n",
    "        heapq.heapify(heap)\n",
    "        return self.bfs(heap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-436ff0e34813>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSolution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpoints\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_min_days\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-21-31741b40fa27>\u001b[0m in \u001b[0;36mfind_min_days\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvisited\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mheapq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheapify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheap\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbfs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheap\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-21-31741b40fa27>\u001b[0m in \u001b[0;36mbfs\u001b[1;34m(self, heap)\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mheap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mcurr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mheapq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheappop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheap\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtypes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtypes\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "m = 3\n",
    "n = 5\n",
    "points = [(1,1),(2,2),(3,1),(5,5),(5,6)]\n",
    "result = Solution(m, n, points)\n",
    "\n",
    "print(result.find_min_days())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResourcePool:\n",
    "    def __init__(self, n):\n",
    "        self.pool = list(range(1, n+1))\n",
    "        self.used = set()\n",
    "        \n",
    "    def allocate(self, x=None):\n",
    "        if x is None:\n",
    "            if self.pool:\n",
    "                x = self.pool.pop(0)\n",
    "                self.used.add(x)\n",
    "        else:\n",
    "            if x not in self.used and x in self.pool:\n",
    "                self.pool.remove(x)\n",
    "                self.used.add(x)\n",
    "        return x\n",
    "    \n",
    "    def release(self, x):\n",
    "        if x in self.used:\n",
    "            self.used.remove(x)\n",
    "            self.pool.append(x)\n",
    "        return\n",
    "    \n",
    "    def get_first_free(self):\n",
    "        if self.pool:\n",
    "            return self.pool[0]\n",
    "        else:\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(input())  # 资源池的范围\n",
    "m = int(input())  # 操作个数\n",
    "rp = ResourcePool(n)\n",
    "\n",
    "for i in range(m):\n",
    "    op, x = map(int, input().split())\n",
    "    if op == 1:\n",
    "        x = rp.allocate()\n",
    "        if x is not None:\n",
    "            print(x)\n",
    "        else:\n",
    "            print(\"NULL\")\n",
    "    elif op == 2:\n",
    "        rp.allocate(x)\n",
    "    elif op == 3:\n",
    "        rp.release(x)\n",
    "\n",
    "print(rp.get_first_free())\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a2e8f04d65c62c49dbc0f2adda76bbd103f82c3255fc54c7e3855bd92e2af645"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
