{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data \n",
    "import torch.optim as optim\n",
    "dtype = torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['i like cat', 'i love coffee', 'i hate milk']\n",
    "sentences_list = \" \".join(sentences).split() # ['i', 'like', 'cat', 'i', 'love'. 'coffee',...]\n",
    "vocab = list(set(sentences_list))\n",
    "word2idx = {w:i for i, w in enumerate(vocab)}\n",
    "idx2word = {i:w for i, w in enumerate(vocab)}\n",
    "vocab_lens = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(sentences):\n",
    "    input_data = []\n",
    "    target_data = []\n",
    "    for sen in sentences:\n",
    "        sen = sen.split()\n",
    "        input_map = [word2idx[i] for i in sen[:-1]]\n",
    "        tar_map = word2idx[sen[-1]]\n",
    "        input_data.append(input_map)\n",
    "        target_data.append(tar_map)\n",
    "    return input_data,target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.TensorDataset at 0x24ddda89e08>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data,target_data = make_data(sentences)\n",
    "input_data,target_data = torch.LongTensor(input_data), torch.LongTensor(target_data)\n",
    "dataset = Data.TensorDataset(input_data,target_data)\n",
    "dataloader = Data.DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 2\n",
    "n_step = 2#输入数据长度\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNLM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NNLM,self).__init__()\n",
    "        self.table_lookup = nn.Embedding(vocab_lens,embedding_dim)\n",
    "        self.linear1 = nn.Linear(n_step*embedding_dim, 64)\n",
    "        self.linear2 =nn.Linear(n_step*embedding_dim,vocab_lens)\n",
    "        self.linear3 = nn.Linear(64,vocab_lens, bias=False)\n",
    "        # 或者直接定义一个参数矩阵\n",
    "        # self.U = nn.Parameter(torch.randn(n_hidden, V).type(dtype))\n",
    "\n",
    "    def forward(self,x):\n",
    "        # input: [batch_size, n_step]\n",
    "        x = self.table_lookup(x) # [batch_size, n_step, embeddding_dim]\n",
    "        x = x.view(-1, n_step*embedding_dim) # [batch_size, n_step*embedding_dim]\n",
    "        hidden_out = F.tanh(self.linear1(x))\n",
    "        out = self.linear2(x) + self.linear3(hidden_out)\n",
    "        return out\n",
    "'''\n",
    "1000 0.001605809316970408\n",
    "1000 0.001312824198976159\n",
    "2000 0.00028981463401578367\n",
    "2000 0.0002321927313460037\n",
    "3000 8.302579226437956e-05\n",
    "3000 6.878139538457617e-05\n",
    "4000 2.443760422465857e-05\n",
    "4000 2.825220326485578e-05\n",
    "5000 8.404219443036709e-06\n",
    "5000 9.65590606938349e-06'''\n",
    "# class NNLM(nn.Module):\n",
    "#   def __init__(self):\n",
    "#     super(NNLM, self).__init__()\n",
    "#     self.C = nn.Embedding(vocab_lens, embedding_dim)\n",
    "#     self.H = nn.Parameter(torch.randn(n_step * embedding_dim, 64).type(dtype))\n",
    "#     self.d = nn.Parameter(torch.randn(64).type(dtype))\n",
    "#     self.b = nn.Parameter(torch.randn(vocab_lens).type(dtype))\n",
    "#     self.W = nn.Parameter(torch.randn(n_step * embedding_dim, vocab_lens).type(dtype))\n",
    "#     self.U = nn.Parameter(torch.randn(64, vocab_lens).type(dtype))\n",
    "\n",
    "#   def forward(self, X):\n",
    "#     '''\n",
    "#     X : [batch_size, n_step]\n",
    "#     '''\n",
    "#     X = self.C(X) # [batch_size, n_step, m]\n",
    "#     X = X.view(-1, n_step * embedding_dim) # [batch_szie, n_step * m]\n",
    "#     hidden_out = torch.tanh(self.d + torch.mm(X, self.H)) # [batch_size, n_hidden]\n",
    "#     output = self.b + torch.mm(X, self.W) + torch.mm(hidden_out, self.U)\n",
    "#     return output\n",
    "'''\n",
    "1000 0.0013060837518423796\n",
    "1000 0.0014915067004039884\n",
    "2000 0.0002582333399914205\n",
    "2000 0.00032884435495361686\n",
    "3000 8.779368363320827e-05\n",
    "3000 7.652943895664066e-05\n",
    "4000 2.4616414521005936e-05\n",
    "4000 3.5523738915799186e-05\n",
    "5000 1.043075644702185e-05\n",
    "5000 8.821448318485636e-06\n",
    "'''\n",
    "model = NNLM()\n",
    "optim = optim.Adam(model.parameters(),lr = 1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\SoftInstall\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 0.001605809316970408\n",
      "1000 0.001312824198976159\n",
      "2000 0.00028981463401578367\n",
      "2000 0.0002321927313460037\n",
      "3000 8.302579226437956e-05\n",
      "3000 6.878139538457617e-05\n",
      "4000 2.443760422465857e-05\n",
      "4000 2.825220326485578e-05\n",
      "5000 8.404219443036709e-06\n",
      "5000 9.65590606938349e-06\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5000):\n",
    "    for datax, datay in dataloader:\n",
    "        pre = model(datax)\n",
    "        loss = criterion(pre, datay)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "\n",
    "        if (epoch + 1) % 1000 == 0:\n",
    "            print(epoch + 1, loss.item())\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat', 'coffee', 'milk']\n"
     ]
    }
   ],
   "source": [
    "# Pred\n",
    "pred = model(input_data).max(1, keepdim=True)[1]\n",
    "print([idx2word[idx.item()] for idx in pred.squeeze()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a2e8f04d65c62c49dbc0f2adda76bbd103f82c3255fc54c7e3855bd92e2af645"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
